{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "s0CTd-R5aAiW"
      },
      "source": [
        "**Introduction**\n",
        "\n",
        "This is a Google Colab notebook in which you can test our deep learning model that predicts right ventricular ejection fraction (RVEF) from 2D apical 4-chamber view echocardiographic videos. For detailed information about our model and the entire data analysis pipeline, please refer to our paper (under review) and GitHub repository (https://github.com/rvenet/RVENet-Demo).\n",
        "\n",
        "This notebook was created to provide a convenient option for testing our model on a few DICOM files. However, if you want to analyze a larger set of DICOM files or modify our code substantially, we recommend running our model on your computer (see the above-referenced GitHub repository).\n",
        "\n",
        "This notebook consists of text cells (similar to this one) and code cells (see below). Code cells must be run sequentially (by pressing the play button in the top left corner of each code cell)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cJYD9erDaB3u"
      },
      "source": [
        "**Step 0 - Set runtime type**\n",
        "\n",
        "Google Colab is a hosted Jupyter notebook service that provides access free of charge to computing resources, including GPUs. To run our code with the GPU enabled, go to *Runtime/Change runtime type* and select *GPU* as *Hardware accelerator*. This is a crucial step as our code will throw errors if you do not select *GPU* as the *Hardware accelerator*!"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zHLz8hW2aD-u"
      },
      "source": [
        "**Step 1 - Install and import required Python packages**\n",
        "\n",
        "Run the following code cell to install and import all required Python packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4gKgVEJZ3VF"
      },
      "outputs": [],
      "source": [
        "!pip install pydicom\n",
        "#!pip install planar\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import pydicom\n",
        "import torch\n",
        "from torchvision import models"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "I4JP9VxcJlD9"
      },
      "source": [
        "**Step 2 - Clone the GitHub repository and import the preprocessing code**\n",
        "\n",
        "Run the following code cell to clone the RVENet-Demo GitHub repository into the Colab environment and import the function required for preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpByrtboKJ-7"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/GerhardHarmsen/RVENet-Demo-no-Planar.git\n",
        "%cd RVENet-Demo\n",
        "\n",
        "from preprocessing import get_preprocessed_frames"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QQLJKXBJaHUm"
      },
      "source": [
        "**Step 3 - Upload your DICOM files - OPTIONAL**\n",
        "\n",
        "Although we provided an example DICOM file that you may use to test our model, you can also analyze your own DICOM file(s). First, run this code cell to create a new folder (` \\content\\dicom_files\\`) for the DICOM files. Then, use the file-explorer pane (which can be opened by clicking on the folder icon on the left sidebar) to upload your files to the created folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvXZJRg2YHsN"
      },
      "outputs": [],
      "source": [
        "# Creating a folder to which users can upload their DICOM files\n",
        "dicom_folder_path = \"/content/dicom_files/\"\n",
        "os.makedirs(dicom_folder_path, exist_ok=True)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "k2L5Fu1MaIPf"
      },
      "source": [
        "**Step 4 - Set required and optional parameters**\n",
        "\n",
        "In this cell, you can set all required and optional parameters that will be used in the next steps of the analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvA6DewHZ3VH"
      },
      "outputs": [],
      "source": [
        "# Set device - DO NOT CHANGE!\n",
        "device = torch.device(\"cuda:0\")\n",
        "# NOTE: To run our model, a CUDA-enabled GPU is required!\n",
        "\n",
        "# Set URL to model weights - DO NOT CHANGE!\n",
        "model_url = \"https://www.dropbox.com/s/d1w0nh1rzclo4ox/full_ensemble_model.pt?dl=1\"\n",
        "\n",
        "# Set URL to example DICOM file - DO NOT CHANGE!\n",
        "example_dicom_url = \"https://www.dropbox.com/s/eqj3uhe1ckijn0y/sample1.dcm?dl=1\"\n",
        "\n",
        "# Path of the folder containing the DICOM files - DO NOT CHANGE!\n",
        "dicom_folder_path = \"/content/dicom_files/\"\n",
        "os.makedirs(dicom_folder_path, exist_ok=True)\n",
        "\n",
        "# Frame rate of the DICOM files (None or a dictionary) - OPTIONAL\n",
        "fps_dict = None\n",
        "# NOTE: If it is set to None (default), the code tries to extract the frame rate from the DICOM tags.\n",
        "# If the frame rate is not available in the DICOM metadata, \n",
        "# the frame rate must be provided for each DICOM file in a dictionary,\n",
        "# in which the keys are the paths of DICOM files and \n",
        "# the values are the corresponding frame rate values as integers\n",
        "# (e.g., {\"/content/dicom_files/sample1.dcm\": 60}).\n",
        "\n",
        "# Heart rate of the patients (None or a dictionary) - OPTIONAL\n",
        "hr_dict = None\n",
        "# NOTE: If it is set to None (default), the code tries to extract the heart rate from the DICOM tags.\n",
        "# If the heart rate is not available in the DICOM metadata, \n",
        "# the heart rate must be provided for each DICOM file in a dictionary,\n",
        "# in which the keys are the paths of DICOM files and \n",
        "# the values are the corresponding heart rate values as integers\n",
        "# (e.g., {\"/content/dicom_files/sample1.dcm\": 71}).\n",
        "\n",
        "# Orientation of the left and right ventricles (\"Stanford\" or \"Mayo\") - OPTIONAL\n",
        "orientation = \"Mayo\"\n",
        "# Mayo – the right ventricle on the right and the left ventricle on the left side.\n",
        "# Stanford – the left ventricle on the right and the right ventricle on the left side."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy_ZPlCXVH7i"
      },
      "source": [
        "**Step 5 - Download model weights and the example DICOM file**\n",
        "\n",
        "By running this code cell, model weights and the example DICOM file will be downloaded to the Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HNnobB-TwG0"
      },
      "outputs": [],
      "source": [
        "# Downloading model weights\n",
        "model_path = \"/content/model.pt\"\n",
        "if not os.path.exists(model_path):\n",
        "  !wget {model_url} -O {model_path}\n",
        "\n",
        "# Downloading the example DICOM file if no DICOM files were uploaded by the user\n",
        "example_dicom_path = \"/content/dicom_files/sample1.dcm\"\n",
        "if not os.listdir(dicom_folder_path):\n",
        "  !wget {example_dicom_url} -O {example_dicom_path}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "mYMZZmqiaJ0B"
      },
      "source": [
        "**Step 6 - Preprocessing**\n",
        "\n",
        "By running this code cell, DICOM file(s) will be loaded and preprocessed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K--h8g90Z3VI"
      },
      "outputs": [],
      "source": [
        "# Searching for DICOM files in the input folder\n",
        "dicom_files = []\n",
        "for dir_path, dir_names, file_names in os.walk(dicom_folder_path):\n",
        "  exclusion_criteria = [\"DICOMDIR\"]\n",
        "  dicom_files += [os.path.join(dir_path, f) for f in file_names \n",
        "                  if not any(x in f for x in exclusion_criteria)]\n",
        "\n",
        "# Loading and preprocessing the data from the DICOM file\n",
        "preprocessed_dicom_data = []\n",
        "preprocessed_dicom_files = []\n",
        "for i, dicom_file_path in enumerate(dicom_files):\n",
        "\n",
        "  # Updating the analysis progress\n",
        "  analysis_progress = \"(\" + str(i + 1) + \"/\" + str(len(dicom_files)) + \")\"\n",
        "\n",
        "  try:\n",
        "    # Checking whether heart rate was provided explicitly by the user\n",
        "    if hr_dict:\n",
        "      if dicom_file_path in hr_dict:\n",
        "        hr = hr_dict[dicom_file_path]\n",
        "    else:\n",
        "      hr = None\n",
        "\n",
        "    # Checking whether frame rate was provided explicitly by the user\n",
        "    if fps_dict:\n",
        "      if dicom_file_path in fps_dict:\n",
        "        fps = fps_dict[dicom_file_path]\n",
        "    else:\n",
        "      fps = None\n",
        "\n",
        "    # Preprocessing the DICOM file\n",
        "    preprocessed_dicom_data.append(get_preprocessed_frames(dicom_file_path, fps, hr, orientation))\n",
        "    preprocessed_dicom_files.append(dicom_file_path)\n",
        "    \n",
        "    # Printing analysis progress\n",
        "    msg_list = [datetime.now().strftime(\"%m-%d-%Y %H:%M:%S\"),\n",
        "                analysis_progress + \" \" + dicom_file_path,\n",
        "                \"Preprocessing was successful!\"]\n",
        "    print(\" - \".join(msg_list))  \n",
        "  except pydicom.filereader.InvalidDicomError:\n",
        "    # Printing error message\n",
        "    msg_list = [datetime.now().strftime(\"%m-%d-%Y %H:%M:%S\"),\n",
        "                analysis_progress + \" \" + dicom_file_path,\n",
        "                \"Invalid DICOM file!\"]\n",
        "    print(\" - \".join(msg_list))\n",
        "    continue\n",
        "  except Exception as err:\n",
        "    # Printing error message\n",
        "    msg_list = [datetime.now().strftime(\"%m-%d-%Y %H:%M:%S\"),\n",
        "                analysis_progress + \" \" + dicom_file_path, str(err)]\n",
        "    print(\" - \".join(msg_list))\n",
        "    continue"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "22neZhuEaMgW"
      },
      "source": [
        "**Step 5: Predict RVEF**\n",
        "\n",
        "As the final step, you can run the model on the preprocessed video(s) to predict RVEF for each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHh5uxZQZ3VJ"
      },
      "outputs": [],
      "source": [
        "# Loading the trained model and sending it to the GPU\n",
        "model = torch.load(model_path, map_location=device)\n",
        "model.eval()\n",
        "model = model.to(device)\n",
        "\n",
        "# Predicting RVEF for each preprocessed video\n",
        "list_of_predicted_rvefs = []\n",
        "list_of_dicom_files = []\n",
        "for i, preprocessed_frames in enumerate(preprocessed_dicom_data):\n",
        "\n",
        "  # Updating the analysis progress\n",
        "  analysis_progress = \"(\" + str(i + 1) + \"/\" + str(len(dicom_files)) + \")\"\n",
        "\n",
        "  try:\n",
        "    # Sending preprocessed frames to the GPU\n",
        "    preprocessed_frames = preprocessed_frames.to(device, dtype=torch.float)\n",
        "\n",
        "    # Predicting RVEF for each cardiac cycle in the given video\n",
        "    cardiac_cycle_predictions = []\n",
        "    for preprocessed_frames_from_a_single_cardiac_cycle in preprocessed_frames:\n",
        "      predicted_rvef_from_one_cardiac_cycle = model(preprocessed_frames_from_a_single_cardiac_cycle)\n",
        "      cardiac_cycle_predictions.append(predicted_rvef_from_one_cardiac_cycle.item())\n",
        "\n",
        "    # Calculating the final predicted RVEF value for the video (i.e., the mean of cardiac cycle predictions)\n",
        "    predicted_rvef = np.mean(cardiac_cycle_predictions)\n",
        "\n",
        "    # Appending the DICOM file path and the predicted RVEF to the lists\n",
        "    list_of_dicom_files.append(preprocessed_dicom_files[i])\n",
        "    list_of_predicted_rvefs.append(predicted_rvef)\n",
        "\n",
        "    # Printing analysis progress\n",
        "    msg_list = [datetime.now().strftime(\"%m-%d-%Y %H:%M:%S\"),\n",
        "                analysis_progress + \" \" + preprocessed_dicom_files[i],\n",
        "                \"Predicted RVEF: {:.3f}%\".format(predicted_rvef)]\n",
        "    print(\" - \".join(msg_list))\n",
        "  except Exception:\n",
        "    # Printing error message\n",
        "    msg_list = [datetime.now().strftime(\"%m-%d-%Y %H:%M:%S\"),\n",
        "                analysis_progress + \" \" + preprocessed_dicom_files[i],\n",
        "                \"Error in predicting RVEF!\"]\n",
        "    print(\" - \".join(msg_list))\n",
        "    continue\n",
        "\n",
        "# Saving prediction results to a CSV file\n",
        "df = pd.DataFrame({\"dicom_file_path\": list_of_dicom_files, \"predicted_rvef\": list_of_predicted_rvefs})\n",
        "df.to_csv(\"/content/predictions.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
